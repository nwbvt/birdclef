{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04733b2-d6a1-4486-bd4a-ca826ddb8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data import BirdClefTrainAudio, BirdClefHarmonics\n",
    "from model import HarmonicModel\n",
    "from mimir import training\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b85096-5540-4643-b89a-9ad5bbc0b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20250403)\n",
    "random.seed(20250403)\n",
    "torch.manual_seed(20250403)\n",
    "torch.cuda.manual_seed(20250403)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc302636-3936-427b-a067-172ea9cbf024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92004ecd-d7f7-4279-9edc-d33875c671d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = BirdClefTrainAudio(data_folder, max_duration=5, sr=16000)\n",
    "cachefile=\"data.pkl\"\n",
    "if os.path.isfile(cachefile):\n",
    "    with open(cachefile, \"rb\") as f:\n",
    "        ds = pickle.load(f)\n",
    "else:\n",
    "    start = time.time()\n",
    "    ds = BirdClefHarmonics(audio, fmin=500, fmax=4000)\n",
    "    print(f\"Loading data took {time.time()-start} seconds\")\n",
    "    with open(cachefile, \"wb\") as f:\n",
    "        pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481c8d4f-c536-417a-bd03-67efa9818da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(weight=torch.tensor(audio.label_weights()).to(training.DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d22f0b-d40a-4bde-ba74-506b42fbbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    return sum(preds.argmax(1) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81ae40f-d2a5-4df4-9481-322766c4ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = training.HyperParameters(model_params={'n_labels': audio.n_labels, 'n_harmonics': 10, \"num_filter_maps\": 64, \"kernel_size\": 128}, \n",
    "                               optimizer_params={'lr': 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd86046-aa1c-4d04-b428-c6246e351676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: Loss=5.28259 val, 5.24245 train Accuracy=0.28571 val 0.28380 train \n",
      "Epoch   1: Loss=5.27685 val, 5.22527 train Accuracy=0.54342 val 0.42742 train \n",
      "Epoch   2: Loss=5.27080 val, 5.21229 train Accuracy=0.47619 val 0.44609 train \n",
      "Epoch   3: Loss=5.26244 val, 5.19938 train Accuracy=0.29132 val 0.27369 train \n",
      "Epoch   4: Loss=5.26171 val, 5.19378 train Accuracy=0.25210 val 0.30107 train \n",
      "Epoch   5: Loss=5.25417 val, 5.18623 train Accuracy=0.29692 val 0.29563 train \n",
      "Epoch   6: Loss=5.25815 val, 5.17914 train Accuracy=0.26891 val 0.26389 train \n",
      "Epoch   7: Loss=5.25504 val, 5.17413 train Accuracy=0.29692 val 0.28131 train \n",
      "Epoch   8: Loss=5.25571 val, 5.17155 train Accuracy=0.22409 val 0.30123 train \n",
      "Epoch   9: Loss=5.25443 val, 5.16826 train Accuracy=0.23529 val 0.29423 train \n",
      "Epoch  10: Loss=5.25496 val, 5.16239 train Accuracy=0.21289 val 0.25891 train \n",
      "Final results: Loss=5.254173755645752 Accuracy=0.29692 \n"
     ]
    }
   ],
   "source": [
    "results, model = training.train(data=ds, model_class = HarmonicModel, hyper_params=hps, loss_fn = loss,\n",
    "                                name=\"convmodel\", pad=True, batch_size=16, metrics={\"Accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fd208-5654-434a-9fff-b6b89f39e21b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
