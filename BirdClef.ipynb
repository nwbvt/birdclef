{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04733b2-d6a1-4486-bd4a-ca826ddb8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data import BirdClefTrainAudio, BirdClefHarmonics\n",
    "from model import HarmonicModel\n",
    "from mimir import training\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b85096-5540-4643-b89a-9ad5bbc0b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20250403)\n",
    "random.seed(20250403)\n",
    "torch.manual_seed(20250403)\n",
    "torch.cuda.manual_seed(20250403)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc302636-3936-427b-a067-172ea9cbf024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92004ecd-d7f7-4279-9edc-d33875c671d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = BirdClefTrainAudio(data_folder, max_duration=5, sr=16000)\n",
    "cachefile=\"data.pkl\"\n",
    "if os.path.isfile(cachefile):\n",
    "    with open(cachefile, \"rb\") as f:\n",
    "        ds = pickle.load(f)\n",
    "else:\n",
    "    start = time.time()\n",
    "    ds = BirdClefHarmonics(audio, fmin=500, fmax=4000)\n",
    "    print(f\"Loading data took {time.time()-start} seconds\")\n",
    "    with open(cachefile, \"wb\") as f:\n",
    "        pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81ae40f-d2a5-4df4-9481-322766c4ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = training.HyperParameters(model_params={'n_labels': audio.n_labels, 'n_harmonics': 10, \"num_filter_maps\": 128}, \n",
    "                               optimizer_params={'lr': 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481c8d4f-c536-417a-bd03-67efa9818da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(weight=torch.tensor(audio.label_weights()).to(training.DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd86046-aa1c-4d04-b428-c6246e351676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: Loss=5.25743 val, 5.23250 train \n",
      "Epoch   1: Loss=5.24952 val, 5.21542 train \n",
      "Epoch   2: Loss=5.25050 val, 5.20460 train \n",
      "Epoch   3: Loss=5.24500 val, 5.19536 train \n",
      "loss: 5.244151, [ 24016/ 25708]"
     ]
    }
   ],
   "source": [
    "results, model = training.train(data=ds, model_class = HarmonicModel, hyper_params=hps, loss_fn = loss,\n",
    "                                name=\"convmodel\", pad=True, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
