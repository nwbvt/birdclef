{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04733b2-d6a1-4486-bd4a-ca826ddb8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data import BirdClefTrainAudio, BirdClefHarmonics, BirdClefClassDS\n",
    "from model import HarmonicModel\n",
    "from mimir import training\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b85096-5540-4643-b89a-9ad5bbc0b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20250403)\n",
    "random.seed(20250403)\n",
    "torch.manual_seed(20250403)\n",
    "torch.cuda.manual_seed(20250403)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc302636-3936-427b-a067-172ea9cbf024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92004ecd-d7f7-4279-9edc-d33875c671d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = BirdClefTrainAudio(data_folder, max_duration=5, sr=16000)\n",
    "cachefile=\"data.pkl\"\n",
    "if os.path.isfile(cachefile):\n",
    "    with open(cachefile, \"rb\") as f:\n",
    "        ds = pickle.load(f)\n",
    "else:\n",
    "    start = time.time()\n",
    "    ds = BirdClefHarmonics(audio, fmin=500, fmax=4000)\n",
    "    print(f\"Loading data took {time.time()-start} seconds\")\n",
    "    with open(cachefile, \"wb\") as f:\n",
    "        pickle.dump(ds, f)\n",
    "class_ds = BirdClefClassDS(audio, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481c8d4f-c536-417a-bd03-67efa9818da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(weight=torch.tensor(audio.class_weights()).to(training.DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d22f0b-d40a-4bde-ba74-506b42fbbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    return sum(preds.argmax(1) == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81ae40f-d2a5-4df4-9481-322766c4ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_hps = training.HyperParameters(model_params={'n_labels': audio.n_classes, 'n_harmonics': 10,\n",
    "                                                   \"num_filter_maps\": 2048, \"kernel_size\": 200, \"hidden\": 32, \"dropout\": 0.5}, \n",
    "                                     optimizer_params={'lr': 2e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd86046-aa1c-4d04-b428-c6246e351676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: Loss=0.55824 val, 0.61058 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch   1: Loss=0.52055 val, 0.58077 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch   2: Loss=0.50478 val, 0.57322 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch   3: Loss=0.50466 val, 0.56719 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch   4: Loss=0.51345 val, 0.57287 train Accuracy=0.97304 val 0.96733 train \n",
      "Epoch   5: Loss=0.49642 val, 0.56429 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch   6: Loss=0.51840 val, 0.57709 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch   7: Loss=0.49509 val, 0.56503 train Accuracy=0.97304 val 0.96740 train \n",
      "Epoch   8: Loss=0.50849 val, 0.57216 train Accuracy=0.97304 val 0.96733 train \n",
      "Epoch   9: Loss=0.50140 val, 0.56320 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch  10: Loss=0.48863 val, 0.55693 train Accuracy=0.97269 val 0.96740 train \n",
      "Epoch  11: Loss=0.50169 val, 0.56326 train Accuracy=0.97269 val 0.96733 train \n",
      "Epoch  12: Loss=0.48880 val, 0.55752 train Accuracy=0.97269 val 0.96740 train \n",
      "Epoch  13: Loss=0.49938 val, 0.58781 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch  14: Loss=0.49051 val, 0.55903 train Accuracy=0.97304 val 0.96736 train \n",
      "Epoch  15: Loss=0.49242 val, 0.56033 train Accuracy=0.97304 val 0.96725 train \n",
      "Final results: Loss=0.4886295199394226 Accuracy=0.97269 \n"
     ]
    }
   ],
   "source": [
    "class_results, class_model = training.train(data=class_ds, model_class = HarmonicModel, hyper_params=class_hps, loss_fn = loss,\n",
    "                                            name=\"harmonicmodel\", pad=True, batch_size=16, metrics={\"Accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471852cd-b6bd-4d5f-9c8a-251c02029709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
